{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 200px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Ateliers: Technologies des grosses data](https://github.com/wikistat/Ateliers-Big-Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reconnaissance de caractères manuscrits](https://github.com/wikistat/Ateliers-Big-Data/2-MNIST) ([MNIST](http://yann.lecun.com/exdb/mnist/)) en <a href=\"https://www.python.org/\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Python_logo_and_wordmark.svg/390px-Python_logo_and_wordmark.svg.png\" style=\"max-width: 120px; display: inline\" alt=\"Python\"/></a> avec <a href=\"http://scikit-learn.org/stable/#\"><img src=\"http://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" style=\"max-width: 100px; display: inline\" alt=\"Scikit-Learn\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Day 1</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Objectif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Même traitement sur les mêmes données cette fois avec Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Lecture des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques dans la fenêtre\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données peuvent être préalablement téléchargées ou directement lues. Ce sont celles originales du site [MNIST DataBase](http://yann.lecun.com/exdb/mnist/) mais préalablement converties au format .csv, certes plus volumineux mais plus facile à lire. Attention le fichier `mnist_train.zip` présent dans le dépôt est compressé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   775  776  777  778  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   779  780  781  782  783  784  \n",
       "0    0    0    0    0    0    2  \n",
       "1    0    0    0    0    0    3  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    2  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "path=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/data/\"\n",
    "Dtrain=pd.read_csv(path+\"mnist_train.csv\",header=None)\n",
    "Dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9   ...   774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0 ...     0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extraction puis suppression de la dernière colonne des labels\n",
    "Ltrain=Dtrain.iloc[:,784]\n",
    "Dtrain.drop(Dtrain.columns[[784]], axis=1,inplace=True)\n",
    "Dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensions de l'échantillon\n",
    "Dtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Même chose pour les données de test\n",
    "Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "Ltest=Dtest.iloc[:,784]\n",
    "Dtest.drop(Dtest.columns[[784]], axis=1,inplace=True)\n",
    "Dtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home-local/pbesse/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:281: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59b5d66630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# affichage d'un chiffre\n",
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(np.matrix(Dtest.iloc[1,:]).reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f59ae6aac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, figsize=(3, 3))\n",
    "plt.imshow(np.matrix(Dtest.iloc[10,:]).reshape(28,28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données ont déjà été normalisées centrées et sont complètes. Elles ne nécessitent pas d'autre \"nettoyage\" au moins rudimentaire.\n",
    "\n",
    "Le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à Scikit-learn montre comment représenter les images des caractères ainsi qu'une ACP qui n'est pas reprise ici. Quelles sont néanmoins les performances de k-means sur un tel volume ?\n",
    "\n",
    "**Ajouter ACP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "tps1 = time.clock()\n",
    "km=KMeans(n_clusters=10,init='k-means++', \n",
    "   n_init=10, max_iter=100, tol=0.01,\n",
    "   precompute_distances=True, verbose=0, \n",
    "   random_state=None, copy_x=True, n_jobs=-1)\n",
    "km.fit(Dtrain)\n",
    "tps2 = time.clock()\n",
    "print(\"Temps execution Kmeans :\", (tps2 - tps1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Ltrain, km.labels_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultat sans grand intérêt mais qui montre la difficulté de regouper les caractères identiques à l'aide de la distance euclidienne usuelle; il y a beaucoup de confusion entre les classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Day 2</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $K$ nearest neighboors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle avec un nombre k \"standard\" de voisins\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "tps1 = time.clock()\n",
    "knn = KNeighborsClassifier(n_neighbors=10,n_jobs=-1)\n",
    "digit_knn=knn.fit(Dtrain, Ltrain) \n",
    "tps2 = time.clock()\n",
    "print(\"Temps de k-nn :\",(tps2 - tps1)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage et estimation de l'erreur de prévision sur l'échantillon test\n",
    "tps1 = time.clock()\n",
    "erreur=1-digit_knn.score(Dtest,Ltest)\n",
    "tps2 = time.clock()\n",
    "print(\"Temps:\",(tps2 - tps1)/60,\"Erreur:\",erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faudrait ré-appliquer la procédure d'otpimisation de $k$ par validation croisée décrite dans le [tutoriel](http://wikistat.fr/pdf/st-tutor3-python-scikit.pdf) d'introduction à scikit-learn. Néanmoins la solution $k=10$ est raisonnable et on retrouve une performance classique sur ce type de données: 3.3%, pour une méthode utilisée sans raffinement. \n",
    "\n",
    "C'est en effet une autre distance qu'il faudrait utiliser avec les $k$ plus proches voisins pour améliorer sensiblement les résultats mais avec un coût beaucoup plus élevé en temps de calcul. Un autre [scénario](http://wikistat.fr/pdf/st-atelier-MINST-tangent-ditance.pdf) propose ainsi le calcul d'une distance tangentielle entre les images ([Simard et al. (1998)](https://hal-ens.archives-ouvertes.fr/file/index/docid/60948/filename/Tangent_distance.pdf)). Le programme Matlab fait appel à un programme en C. L'intégration dans du code python plutôt que Matlab resterait à faire..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <FONT COLOR=\"Red\">Day 3</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les forêts aléatoires sont également une approche raisonnable, à moindre coût de développement, sur ces données. Analyser en détail la liste des paramètres proposés dans l'implémentation de cet algorithme. Consulter pour ce faire la [documentation](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) en ligne.\n",
    "\n",
    "Les valeurs par défaut des paramètres sont utilisées sauf pour le nombre d'arbres: 100 au lieu de 10, et le nombre de processeurs utilisés: -1 au lieu de 1 (tous sont utilisés sauf 1 pour le système). Attention, tous les paramètres disponibles ne sont pas listés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "tps0 = time.clock()\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "   criterion='gini', max_depth=None, min_samples_split=2, \n",
    "   min_samples_leaf=1, max_features='auto', max_leaf_nodes=None, \n",
    "   bootstrap=True, oob_score=True, n_jobs=-1,random_state=None, verbose=0)\n",
    "rf.fit(Dtrain,Ltrain)\n",
    "tps1 = time.clock()\n",
    "print(\"Temps de configutration RF :\" ,tps1 - tps0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur out-of-bag\n",
    "erreur_oob=1-rf.oob_score_\n",
    "tps2 = time.clock()\n",
    "print(\"Temps execution RF :\", tps2 - tps0, \"Erreur oob:\", erreur_oob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# erreur sur l'échantillon test\n",
    "1-rf.score(Dtest,Ltest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Ltest, rf.predict(Dtest))\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme pour les $k$ plus proches voisins, il serait utile d'optimiser certains paramètres dont le nombre d'arbres et sans doute *max_features*. L'optimisation de l'erreur *out-of-bag* plutôt qu'une procédure lourde  de validaiton croisée serait bienvenue. D'autre part, la restriction de la profondeur max des arbres pourrait réduire sensiblement les temps de calcul mais cela ne semble pas nécessaire d'autant que c'est un paramètre critique pour la qualité de la prévision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.utils as ku\n",
    "import keras.models as km\n",
    "import keras.layers as kl\n",
    "import keras.optimizers as ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture des données d'apprentissage\n",
    "N_classes = 10\n",
    "\n",
    "# path=\"\" # Si les données sont dans le répertoire courant sinon:\n",
    "# path=\"../2-MNIST/\"\n",
    "# Dtrain=pd.read_csv(path+\"mnist_train.csv\",header=None)\n",
    "X_train = Dtrain\n",
    "Y_train = Ltrain\n",
    "\n",
    "# Dtest=pd.read_csv(path+\"mnist_test.csv\",header=None)\n",
    "X_test = Dtest\n",
    "Y_test = Ltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_cat = ku.to_categorical(Y_train, N_classes)\n",
    "Y_test_cat = ku.to_categorical(Y_test, N_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a normalisation that is really important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.2438 - acc: 0.9247 - val_loss: 0.1077 - val_acc: 0.9649\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1032 - acc: 0.9690 - val_loss: 0.1026 - val_acc: 0.9685\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0756 - acc: 0.9777 - val_loss: 0.0652 - val_acc: 0.9804\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.0606 - acc: 0.9818 - val_loss: 0.0930 - val_acc: 0.9734\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0526 - acc: 0.9836 - val_loss: 0.0764 - val_acc: 0.9813\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0438 - acc: 0.9863 - val_loss: 0.0795 - val_acc: 0.9806\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0377 - acc: 0.9884 - val_loss: 0.0751 - val_acc: 0.9811\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0711 - val_acc: 0.9826\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0819 - val_acc: 0.9838\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0284 - acc: 0.9920 - val_loss: 0.0907 - val_acc: 0.9817\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0272 - acc: 0.9920 - val_loss: 0.0942 - val_acc: 0.9803\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0250 - acc: 0.9928 - val_loss: 0.0846 - val_acc: 0.9823\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0232 - acc: 0.9935 - val_loss: 0.0925 - val_acc: 0.9837\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0229 - acc: 0.9938 - val_loss: 0.0995 - val_acc: 0.9823\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0208 - acc: 0.9946 - val_loss: 0.1112 - val_acc: 0.9802\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0198 - acc: 0.9944 - val_loss: 0.0992 - val_acc: 0.9836\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0198 - acc: 0.9947 - val_loss: 0.1129 - val_acc: 0.9823\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0207 - acc: 0.9947 - val_loss: 0.0951 - val_acc: 0.9838\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.1152 - val_acc: 0.9819\n",
      "Epoch 20/20\n",
      "52992/60000 [=========================>....] - ETA: 1s - loss: 0.0183 - acc: 0.9955"
     ]
    }
   ],
   "source": [
    "# Data normalization\n",
    "X_train_norm = X_train/255\n",
    "X_test_norm = X_test/255\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 20\n",
    "\n",
    "model = km.Sequential()\n",
    "model.add(kl.Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(512, activation='relu'))\n",
    "model.add(kl.Dropout(0.2))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "model.summary()\n",
    "# Apprentissage\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=ko.RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "history = model.fit(X_train_norm, Y_train_cat,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test_norm, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_mpl_norm = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.278151943779\n",
      "Test accuracy: 0.9827\n",
      "Time Running: 325.15 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1124</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>965</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>868</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>943</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1019</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>946</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3    4    5    6     7    8    9\n",
       "0  975     1     0    1    0    1    0     1    1    0\n",
       "1    1  1124     3    1    0    1    1     1    3    0\n",
       "2    6     0  1008    2    4    0    2     7    2    1\n",
       "3    0     0     2  995    0    2    0     6    3    2\n",
       "4    1     0     0    0  965    0    6     3    0    7\n",
       "5    3     0     0   12    1  868    2     1    4    1\n",
       "6    5     2     0    1    3    3  943     0    1    0\n",
       "7    0     1     6    0    0    0    0  1019    0    2\n",
       "8    6     1     1    7    2    0    1     8  946    2\n",
       "9    2     2     0    2    9    1    0     8    1  984"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_mpl_norm = model.evaluate(X_test, Y_test_cat, verbose=0)\n",
    "predict_mpl_norm = model.predict(X_test)\n",
    "print('Test loss:', score_mpl_norm[0])\n",
    "print('Test accuracy:', score_mpl_norm[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_mpl_norm )\n",
    "pd.DataFrame(confusion_matrix(Y_test, predict_mpl_norm.argmax(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Convolutional Network\n",
    "Les propriété d'invariance par translation introduites par les couches opérant une convolution des images ont un impact important sur la qualité des résultats.\n",
    "### Réseau\n",
    "Test d'un réseau de convolution constitué de 7 couches: \n",
    "\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche de convolution 2D, avec fenêtre de taille 3x3 et une fonction d'activation *relu*\n",
    "* Une couche max pooling de fenêtre 2x2\n",
    "* Une couche *dropout* où 25% des neurones sont desactivés\n",
    "* Une couche *Flatten* transforme les images $N \\times N$ en vecteurs $N^2$.\n",
    "* Une couche classique de 128 neurones\n",
    "* Une couche dropout ou 50% des neurones sont desactivés\n",
    "\n",
    "Une couche *softmax* fournit la classification\n",
    "\n",
    "### Format des données\n",
    "\n",
    "Dans les exemples précédents. Les données était \"applaties\". Une imade de $28\\times 28=784$ pixels est considérée comme un vecteur. \n",
    "\n",
    "Pour pouvoir utiliser le principe de la convolution la structure des images est conservée. Une image n'est pas un vecteur de tailles $784\\times 1$ mais une matrice de taille $28\\times 28$. Ainsi `X_train` est réorganisée en cube ou multitableau de dimensions $60000\\times 28\\times 28$ pour être utilisé dans un réseau de convolution.\n",
    "\n",
    "Avec **Keras** `X_train` doit même être de dimensions $60000\\times 28\\times 28\\times 1$. La dernière dimension, de taille 1 peut paraitre inutile car dans le cas des données *MNIST* les pixels ne sont décrits qu'avec un seul niveau de gris. Cependant, des images couleurs en RGB sont généralement codées avec trois niveaux d'intensité (Rouge, Vert et Bleus) correspondant à la quatrième dimension comportant 3 valeurs. \n",
    "\n",
    "Noter également que l'utilisation des couches de convolution rend inutile la normalisation préalable des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_conv = X_train.values.reshape(60000, 28, 28, 1)\n",
    "X_test_conv = X_test.values.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# descrition du réseau\n",
    "model = km.Sequential()\n",
    "model.add(kl.Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(28,28, 1), data_format=\"channels_last\"))\n",
    "model.add(kl.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(kl.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(kl.Dropout(0.25))\n",
    "model.add(kl.Flatten())\n",
    "model.add(kl.Dense(128, activation='relu'))\n",
    "model.add(kl.Dropout(0.5))\n",
    "model.add(kl.Dense(N_classes, activation='softmax'))\n",
    "# Résumé\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 1.9011 - acc: 0.8277 - val_loss: 0.0759 - val_acc: 0.9774\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.1247 - acc: 0.9650 - val_loss: 0.0482 - val_acc: 0.9850\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0837 - acc: 0.9757 - val_loss: 0.0411 - val_acc: 0.9876\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0659 - acc: 0.9814 - val_loss: 0.0366 - val_acc: 0.9879\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0576 - acc: 0.9841 - val_loss: 0.0403 - val_acc: 0.9882\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.0489 - acc: 0.9863 - val_loss: 0.0379 - val_acc: 0.9890\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 114s 2ms/step - loss: 0.0420 - acc: 0.9872 - val_loss: 0.0462 - val_acc: 0.9879\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0379 - acc: 0.9888 - val_loss: 0.0300 - val_acc: 0.9918\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 119s 2ms/step - loss: 0.0342 - acc: 0.9898 - val_loss: 0.0361 - val_acc: 0.9910\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 122s 2ms/step - loss: 0.0323 - acc: 0.9907 - val_loss: 0.0368 - val_acc: 0.9905\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 139s 2ms/step - loss: 0.0303 - acc: 0.9909 - val_loss: 0.0452 - val_acc: 0.9902\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0295 - acc: 0.9916 - val_loss: 0.0474 - val_acc: 0.9902\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 116s 2ms/step - loss: 0.0283 - acc: 0.9919 - val_loss: 0.0367 - val_acc: 0.9907\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0262 - acc: 0.9920 - val_loss: 0.0379 - val_acc: 0.9907\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 118s 2ms/step - loss: 0.0264 - acc: 0.9925 - val_loss: 0.0435 - val_acc: 0.9909\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0245 - acc: 0.9927 - val_loss: 0.0461 - val_acc: 0.9893\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 132s 2ms/step - loss: 0.0255 - acc: 0.9929 - val_loss: 0.0451 - val_acc: 0.9911\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0249 - acc: 0.9933 - val_loss: 0.0423 - val_acc: 0.9907\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 115s 2ms/step - loss: 0.0238 - acc: 0.9932 - val_loss: 0.0518 - val_acc: 0.9900\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 121s 2ms/step - loss: 0.0239 - acc: 0.9935 - val_loss: 0.0455 - val_acc: 0.9902\n"
     ]
    }
   ],
   "source": [
    "# Apprentissage\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=ko.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "ts=time.time()\n",
    "model.fit(X_train_conv, Y_train_cat,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test_conv, Y_test_cat))\n",
    "te=time.time()\n",
    "t_train_conv = te-ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.045543774603\n",
      "Test accuracy: 0.9902\n",
      "Time Running: 2414.81 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>975</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1131</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>882</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1013</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>965</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3    4    5    6     7    8    9\n",
       "0  975     0     2     0    0    0    1     1    1    0\n",
       "1    0  1131     2     1    0    1    0     0    0    0\n",
       "2    1     1  1024     0    1    0    1     4    0    0\n",
       "3    0     0     1  1003    0    3    0     2    1    0\n",
       "4    0     0     0     0  970    0    4     0    2    6\n",
       "5    1     0     1     5    0  882    1     0    1    1\n",
       "6    4     3     0     0    1    1  948     0    1    0\n",
       "7    0     3     7     0    1    0    0  1013    1    3\n",
       "8    3     0     2     1    0    1    0     1  965    1\n",
       "9    1     1     0     4    4    2    0     3    3  991"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_conv = model.evaluate(X_test_conv, Y_test_cat, verbose=0)\n",
    "predict_conv = model.predict(X_test_conv)\n",
    "print('Test loss:', score_conv[0])\n",
    "print('Test accuracy:', score_conv[1])\n",
    "print(\"Time Running: %.2f seconds\" %t_train_conv )\n",
    "pd.DataFrame(confusion_matrix(Y_test, predict_conv.argmax(1)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
