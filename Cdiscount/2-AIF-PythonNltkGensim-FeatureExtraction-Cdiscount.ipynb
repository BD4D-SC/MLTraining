{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "<a href=\"http://www.math.univ-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo_imt.jpg\" style=\"float:right; max-width: 250px; display: inline\" alt=\"IMT\"/> </a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction des caractéristiques ou *features*\n",
    "\n",
    "Les données textuelles ne peuvent pas être utilisés directment dans les différents algorithmes de d'apprentissage statistiques. Nous allons voir dans ce tutoriel plusieurs technique permettant de traduires les données textuelles sous formes de vecteur numérique : \n",
    "\n",
    "\n",
    "Nombresue fonction de vectorisation présente dans scikit-learn :\n",
    "\n",
    "* `One-Hot-Encoder`\n",
    "* `Tf-Idf`\n",
    "* `Hashing`\n",
    "\n",
    "Word Embedding dans la librairies gensim :\n",
    "\n",
    "* `Word2Vec`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Téléchargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Importation des librairies utilisées\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import itertools\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Téléchargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_clean_stem = pd.read_csv(\"data/cdiscount_test_clean_stem.csv\").fillna(\"\")\n",
    "data_train_clean_stem = pd.read_csv(\"data/cdiscount_train_clean_stem.csv\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On créé un dossier dans lequel nous allons sauvegarder les DataFrame constitués des features que l'on va construire dans ce notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_OUTPUT_DIR = \"data/features\"\n",
    "if not(os.path.isdir(\"data/features\")):\n",
    "    os.mkdir(\"data/features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans un premier temps on considère seulement la colonne *Description* de nos `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = data_train_clean_stem[\"Description\"].values\n",
    "test_array = data_test_clean_stem[\"Description\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorisaton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot-Encoding\n",
    "\n",
    "* **One-Hot-Encoding** ...\n",
    "\n",
    "possibilité de ngram/Decrire les paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95000x56624 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1119190 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "extr_cv = CountVectorizer(binary=False)\n",
    "data_train_OHE = extr_cv.fit_transform(train_array)\n",
    "data_train_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56624"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = extr_cv.get_feature_names()\n",
    "N_vocabulary = len(vocabulary)\n",
    "N_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affiche la première ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter pavilion mah ion batter pavilion mah ioncaracterist voir present\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41187</td>\n",
       "      <td>present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54416</td>\n",
       "      <td>voir</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26713</td>\n",
       "      <td>ioncaracterist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26704</td>\n",
       "      <td>ion</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31648</td>\n",
       "      <td>mah</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>38751</td>\n",
       "      <td>pavilion</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4784</td>\n",
       "      <td>batter</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices           token  weight\n",
       "0    41187         present       1\n",
       "1    54416            voir       1\n",
       "2    26713  ioncaracterist       1\n",
       "3    26704             ion       1\n",
       "4    31648             mah       2\n",
       "5    38751        pavilion       2\n",
       "6     4784          batter       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = 0\n",
    "\n",
    "rw = data_train_OHE.getrow(ir)\n",
    "print(train_array[ir])\n",
    "pd.DataFrame([(v, vocabulary[v], k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"token\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x56624 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 56875 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_OHE = extr_cv.transform(test_array)\n",
    "data_test_OHE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sel guerand epic verrin sel guerand epic verrin composit ingredient sel guerand kashmir masal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>token</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11416</td>\n",
       "      <td>composit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18243</td>\n",
       "      <td>epic</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23630</td>\n",
       "      <td>guerand</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26214</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32339</td>\n",
       "      <td>masal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>46174</td>\n",
       "      <td>sel</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>53740</td>\n",
       "      <td>verrin</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices       token  weight\n",
       "0    11416    composit       1\n",
       "1    18243        epic       2\n",
       "2    23630     guerand       3\n",
       "3    26214  ingredient       1\n",
       "4    32339       masal       1\n",
       "5    46174         sel       3\n",
       "6    53740      verrin       2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = 5\n",
    "\n",
    "rw = data_test_OHE.getrow(ir)\n",
    "print(test_array[ir])\n",
    "pd.DataFrame([(v, vocabulary[v], k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"token\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF¶\n",
    "\n",
    "* **TF-IDF**. Le TF-IDF permet de faire ressortir l'importance relative de chaque mot $m$ (ou couples de mots consécutifs) dans un texte-produit ou un descriptif $d$, par rapport à la liste entière des produits. La fonction $TF(m,d)$ compte le nombre d'occurences du mot $m$ dans le descriptif $d$. La fonction $IDF(m)$ mesure l'importance du terme dans l'ensemble des documents ou descriptifs en donnant plus de poids aux termes les moins fréquents car considérés comme les plus discriminants (motivation analogue à celle de la métrique du chi2 en anamlyse des correspondance). $IDF(m,l)=\\log\\frac{D}{f(m)}$ où $D$ est le nombre de documents, la taille de l'échantillon d'apprentissage, et $f(m)$ le nombre de documents ou descriptifs contenant le mot $m$. La nouvelle variable ou *features* est $V_m(l)=TF(m,l)\\times IDF(m,l)$.\n",
    "\n",
    "* Comme pour les transformations des variables quantitatives (centrage, réduction), la même transformation c'est-à-dire les mêmes pondérations, est calculée sur l'achantillon d'apprentissage et appliquée à celui de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utiliser la fonction TfidfVectorizer qui permet de parser également le texte\n",
    "\n",
    "On fixe le paramètre `norm` = False pour rendre les résultats plus explicite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95000x56624 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1119190 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vec = TfidfVectorizer( ngram_range=(1,1), norm = False)\n",
    "data_train_TFIDF = vec.fit_transform(train_array)\n",
    "data_train_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56624"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vec.get_feature_names()\n",
    "N_vocabulary = len(vocabulary)\n",
    "N_vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter pavilion mah ion batter pavilion mah ioncaracterist voir present\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>token</th>\n",
       "      <th>idf</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4784</td>\n",
       "      <td>batter</td>\n",
       "      <td>3.599301</td>\n",
       "      <td>7.198601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38751</td>\n",
       "      <td>pavilion</td>\n",
       "      <td>4.742069</td>\n",
       "      <td>9.484137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31648</td>\n",
       "      <td>mah</td>\n",
       "      <td>3.652676</td>\n",
       "      <td>7.305352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26704</td>\n",
       "      <td>ion</td>\n",
       "      <td>4.199600</td>\n",
       "      <td>4.199600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26713</td>\n",
       "      <td>ioncaracterist</td>\n",
       "      <td>7.081745</td>\n",
       "      <td>7.081745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>54416</td>\n",
       "      <td>voir</td>\n",
       "      <td>1.334262</td>\n",
       "      <td>1.334262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>41187</td>\n",
       "      <td>present</td>\n",
       "      <td>1.340531</td>\n",
       "      <td>1.340531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices           token       idf    weight\n",
       "0     4784          batter  3.599301  7.198601\n",
       "1    38751        pavilion  4.742069  9.484137\n",
       "2    31648             mah  3.652676  7.305352\n",
       "3    26704             ion  4.199600  4.199600\n",
       "4    26713  ioncaracterist  7.081745  7.081745\n",
       "5    54416            voir  1.334262  1.334262\n",
       "6    41187         present  1.340531  1.340531"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = 0\n",
    "\n",
    "rw = data_train_TFIDF.getrow(ir)\n",
    "print(train_array[ir])\n",
    "pd.DataFrame([(v, vocabulary[v], vec.idf_[v], k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"token\",\"idf\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentez, Comment evolue les poids en changeant les paramètre smooth idf, sublinear_tf?\n",
    "\n",
    "En cchangean le nombre de ngram?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On applique maintenant le `vectorizer` sur le jeu de données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5000x56624 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56875 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test_TFIDF = vec.transform(test_array)\n",
    "data_test_TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si le tf est recalculé pour chaque ligne, le même idf est utilisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sel guerand epic verrin sel guerand epic verrin composit ingredient sel guerand kashmir masal\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>token</th>\n",
       "      <th>idf</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53740</td>\n",
       "      <td>verrin</td>\n",
       "      <td>10.515733</td>\n",
       "      <td>21.031465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46174</td>\n",
       "      <td>sel</td>\n",
       "      <td>7.594108</td>\n",
       "      <td>22.782325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32339</td>\n",
       "      <td>masal</td>\n",
       "      <td>11.768496</td>\n",
       "      <td>11.768496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26214</td>\n",
       "      <td>ingredient</td>\n",
       "      <td>8.654980</td>\n",
       "      <td>8.654980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23630</td>\n",
       "      <td>guerand</td>\n",
       "      <td>11.363030</td>\n",
       "      <td>34.089091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18243</td>\n",
       "      <td>epic</td>\n",
       "      <td>8.654980</td>\n",
       "      <td>17.309960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11416</td>\n",
       "      <td>composit</td>\n",
       "      <td>5.512745</td>\n",
       "      <td>5.512745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices       token        idf     weight\n",
       "0    53740      verrin  10.515733  21.031465\n",
       "1    46174         sel   7.594108  22.782325\n",
       "2    32339       masal  11.768496  11.768496\n",
       "3    26214  ingredient   8.654980   8.654980\n",
       "4    23630     guerand  11.363030  34.089091\n",
       "5    18243        epic   8.654980  17.309960\n",
       "6    11416    composit   5.512745   5.512745"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = 5\n",
    "\n",
    "rw = data_test_TFIDF.getrow(ir)\n",
    "print(test_array[ir])\n",
    "pd.DataFrame([(v, vocabulary[v], vec.idf_[v], k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"token\",\"idf\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hashing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Hashage**. Il permet de réduire l'espace des variables (taille du dictionnaire) en un nombre limité et fixé a priori `n_hash` de caractéristiques. Il repose sur la définition d'une fonction de hashage, $h$ qui à un indice $j$ défini dans l'espace des entiers naturels, renvoie un indice $i=h(j)$ dans dans l'espace réduit (1 à n_hash) des caractéristiques. Ainsi le poids de l'indice $i$, du nouvel espace, est l'association de tous les poids d'indice $j$ tels que $i=h(j)$ de l'espace originale. Ici, les poids sont associés d'après la méthode décrite par Weinberger et al. (2009).\n",
    "\n",
    "N.B. $h$ n'est pas généré aléatoirement. Ainsi pour un même fichier d'apprentissage (ou de test) et pour un même entier n_hash, le résultat de la fonction de hashage est identique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a Dictionnary as an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import FeatureHasher\n",
    "nb_hash = 300\n",
    "\n",
    "feathash = FeatureHasher(nb_hash)\n",
    "train_dict_array  = map(lambda x : collections.Counter(x.split(\" \")), train_array)\n",
    "data_train_hash = feathash.fit_transform(train_dict_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95000x300 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1093403 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_hash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter pavilion mah ion batter pavilion mah ioncaracterist voir present\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>204</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>220</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>274</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices  weight\n",
       "0       14     2.0\n",
       "1       36     1.0\n",
       "2       57     2.0\n",
       "3      175     1.0\n",
       "4      204     2.0\n",
       "5      220    -1.0\n",
       "6      274     1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ir = 0\n",
    "\n",
    "rw = data_train_hash.getrow(ir)\n",
    "print(train_array[ir])\n",
    "pd.DataFrame([(v, k)  for k,v in zip(rw.data,rw.indices)], columns=[\"indices\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduit la taille de la matrice, MAIS pas de fonction inverse transform. \n",
    "Resultat beaucoup moin facilement compréhensible\n",
    "Efficace que si vraient beaucoup de ligne (>100.000)\n",
    "\n",
    "Il est ensuite possible de passer la nouvelle matrice *hasher* (`data_train_hash`) directement dans un algorithme d'apprentissage, ou bien de combiner ces poids avec une fonction de TFIDF\n",
    "\n",
    "Cette fois la fonction `TFIDFTransformer`est utilisé, ne considère pas les string, mais les tf comme les poids présent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<95000x300 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1085031 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "vec =  TfidfTransformer(norm = False)\n",
    "data_train_HTfidf = vec.fit_transform(data_train_hash)\n",
    "data_train_HTfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batter pavilion mah ion batter pavilion mah ioncaracterist voir present\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indices</th>\n",
       "      <th>idf_</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>274</td>\n",
       "      <td>1.309974</td>\n",
       "      <td>1.309974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>1.325886</td>\n",
       "      <td>-1.325886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204</td>\n",
       "      <td>3.178517</td>\n",
       "      <td>6.357033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175</td>\n",
       "      <td>3.764965</td>\n",
       "      <td>3.764965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>3.506969</td>\n",
       "      <td>7.013938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>36</td>\n",
       "      <td>5.266455</td>\n",
       "      <td>5.266455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14</td>\n",
       "      <td>3.283309</td>\n",
       "      <td>6.566618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   indices      idf_    weight\n",
       "0      274  1.309974  1.309974\n",
       "1      220  1.325886 -1.325886\n",
       "2      204  3.178517  6.357033\n",
       "3      175  3.764965  3.764965\n",
       "4       57  3.506969  7.013938\n",
       "5       36  5.266455  5.266455\n",
       "6       14  3.283309  6.566618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ir = 0\n",
    "\n",
    "rw = data_train_HTfidf.getrow(ir)\n",
    "print(train_array[ir])\n",
    "pd.DataFrame([(v, vec.idf_[v], k)  for k,v in zip(rw.data, rw.indices)], columns=[\"indices\",\"idf_\",\"weight\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Vectorize Vector\n",
    "\n",
    "De nombreux paramètres a regler entraine donc un un très grand nombre de combinaison.\n",
    "\n",
    "ici nous créer seulement par défault 4 jeu de données avec count et TFIDF chacun avec et sans hashin de taille 300.\n",
    "\n",
    "A vous de jouer sur d'autre paramètre nombre de gram, taille de la fonction de hashing, colonne pris en compte ... pour générer d'autre dataset et tester leur influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de Vectorisation\n",
    "\n",
    "on créé deux fonctions `vectorizer_train` and `apply_vectorizer` afin de générer automatiquement différent dataframe d'apprentissage et de test vectorisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def vectorizer_train(df, columns=['Description'], nb_hash=None, nb_gram = 1, vectorizer = \"tfidf\" , binary = False):\n",
    "    \n",
    "    data_array = [\" \".join(line) for line in df[columns].values]\n",
    "    \n",
    "    # Hashage\n",
    "    if nb_hash is None:\n",
    "        feathash = None\n",
    "        if vectorizer == \"tfidf\":\n",
    "            vec = TfidfVectorizer(ngram_range=(1,nb_gram))\n",
    "            data_vec = vec.fit_transform(data_array)\n",
    "        else:\n",
    "            vec = CountVectorizer(binary=binary)\n",
    "            data_vec = vec.fit_transform(data_array)\n",
    "    else:\n",
    "        data_dic_array = [collections.Counter(line.split(\" \")) for line in data_array]\n",
    "        feathash = FeatureHasher(nb_hash)\n",
    "        data_hash = feathash.fit_transform(data_dic_array)\n",
    "        \n",
    "        if vectorizer==\"tfidf\":\n",
    "            vec =  TfidfTransformer()\n",
    "            data_vec =  vec.fit_transform(data_hash)\n",
    "        else:\n",
    "            vec = None\n",
    "            data_vec = data_hash\n",
    "\n",
    "    return vec, feathash, data_vec\n",
    "\n",
    "\n",
    "\n",
    "def apply_vectorizer(df, vec, feathash, columns =['Description', 'Libelle', 'Marque']):\n",
    "    \n",
    "    data_array = [\" \".join(line) for line in df[columns].values]\n",
    "    \n",
    "    #Hashage\n",
    "    if feathash is None:\n",
    "        data_hash = data_array\n",
    "    else:\n",
    "        data_dic_array = [collections.Counter(line.split(\" \")) for line in data_array]\n",
    "        data_hash = feathash.transform(data_dic_array)\n",
    "    \n",
    "    if vec is None:\n",
    "        data_vec = data_hash\n",
    "    else:\n",
    "        data_vec = vec.transform(data_hash)\n",
    "    return data_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_hash : None, vectorizer : count\n",
      "Runing time for vectorization : 1.3 seconds\n",
      "Train shape : (95000, 56624)\n",
      "Test shape : (5000, 56624)\n",
      "nb_hash : 300, vectorizer : count\n",
      "Runing time for vectorization : 1.1 seconds\n",
      "Train shape : (95000, 300)\n",
      "Test shape : (5000, 300)\n",
      "nb_hash : 10000, vectorizer : count\n",
      "Runing time for vectorization : 1.1 seconds\n",
      "Train shape : (95000, 10000)\n",
      "Test shape : (5000, 10000)\n",
      "nb_hash : None, vectorizer : tfidf\n",
      "Runing time for vectorization : 1.7 seconds\n",
      "Train shape : (95000, 56624)\n",
      "Test shape : (5000, 56624)\n",
      "nb_hash : 300, vectorizer : tfidf\n",
      "Runing time for vectorization : 1.1 seconds\n",
      "Train shape : (95000, 300)\n",
      "Test shape : (5000, 300)\n",
      "nb_hash : 10000, vectorizer : tfidf\n",
      "Runing time for vectorization : 1.0 seconds\n",
      "Train shape : (95000, 10000)\n",
      "Test shape : (5000, 10000)\n"
     ]
    }
   ],
   "source": [
    "parameters = [[None, \"count\"],\n",
    "              [300, \"count\"],\n",
    "              [10000,\"count\"],\n",
    "              [None, \"tfidf\"],\n",
    "              [300, \"tfidf\"],\n",
    "             [10000,\"tfidf\"]]\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "for nb_hash, vectorizer in parameters:\n",
    "    ts = time.time()\n",
    "    vec, feathash, data_train_vec = vectorizer_train(data_train_clean_stem, nb_hash=nb_hash, vectorizer = vectorizer)\n",
    "    data_test_vec = apply_vectorizer(data_test_clean_stem, vec, feathash)\n",
    "    te = time.time()\n",
    "    \n",
    "    print(\"nb_hash : \" + str(nb_hash) + \", vectorizer : \" + str(vectorizer))\n",
    "    print(\"Runing time for vectorization : %.1f seconds\" %(te-ts))\n",
    "    print(\"Train shape : \" + str(data_train_vec.shape))\n",
    "    print(\"Test shape : \" + str(data_test_vec.shape))\n",
    "\n",
    "    \n",
    "    sparse.save_npz(DATA_OUTPUT_DIR +\"/vec_train_nb_hash_\" + str(nb_hash) + \"_vectorizer_\" + str(vectorizer), data_train_vec)\n",
    "    sparse.save_npz(DATA_OUTPUT_DIR +\"/vec_test_nb_hash_\" + str(nb_hash) + \"_vectorizer_\" + str(vectorizer), data_test_vec)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "import nltk \n",
    "stemmer=nltk.stem.SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array_token = [line.split(\" \") for line in train_array]\n",
    "test_array_token = [line.split(\" \") for line in test_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features_dimension = 300\n",
    "sg = 1\n",
    "hs = 0\n",
    "negative = 10\n",
    "X = train_array_token\n",
    "N_train = len(X)\n",
    "#sg (int {1, 0}) – Defines the training algorithm. If 1, skip-gram is employed; otherwise, CBOW is used.\n",
    "\n",
    "\n",
    "#hs (int {1,0}) – If 1, hierarchical softmax will be used for model training. \n",
    "#If set to 0, and negative is non-zero, negative sampling will be used.\n",
    "\n",
    "#negative (int) – If > 0, negative sampling will be used, the int for negative specifies how many “noise words” should be drawn (usually between 5-20). \n",
    "#If set to 0, no negative sampling is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilisation d'un modèle appris sur un corpus de Wikipedia en français. Disponible sur le dépôt de \n",
    "[Kyubyong Park](https://github.com/Kyubyong/wordvectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning Word2Vec learning\n",
      "Params are : Fdim_300_sg_0_hs_0_negative_10_model\n",
      "{'learning_time': 15.90987777709961, 'vocab_size': 56625, 'sg': 0, 'negative': 10, 'hs': 0}\n",
      "Start learning Word2Vec learning\n",
      "Params are : Fdim_300_sg_1_hs_0_negative_10_model\n",
      "{'learning_time': 54.87539887428284, 'vocab_size': 56625, 'sg': 1, 'negative': 10, 'hs': 0}\n"
     ]
    }
   ],
   "source": [
    "model_dic = {}\n",
    "for sg in [0,1]:\n",
    "    print(\"Start learning Word2Vec learning\")\n",
    "    print(\"Params are : Fdim_%d_sg_%d_hs_%d_negative_%d_model\" %(Features_dimension, sg, hs, negative))\n",
    "    ts = time.time()\n",
    "    model = gensim.models.Word2Vec(X, sg=sg, hs=hs, negative=negative, min_count=1, size=Features_dimension)\n",
    "    te = time.time()\n",
    "    t_learning = te-ts\n",
    "\n",
    "    # Metadata\n",
    "    N_vocab, feature_dim = model.wv.vectors.shape\n",
    "    metadata = {\"learning_time\" : t_learning, \"vocab_size\" : N_vocab, \"sg\" : sg, \"negative\": negative, \"hs\":hs}\n",
    "    print(metadata)\n",
    "    \n",
    "    model_name = \"skip-gram\" if sg==1 else \"CBOW\"\n",
    "    model_dic.update({model_name : model})\n",
    "\n",
    "model_online_dir = \"data/fr/fr.bin\"\n",
    "model = gensim.models.Word2Vec.load(model_online_dir)\n",
    "model_dic.update({\"online\" : model})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most similar world\n",
    "Résultats pertinent seulement si N_train=1.000.000, 100.000 trop peu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict_output_word([\"homm\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for word : homme\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>femm</td>\n",
       "      <td>unisex</td>\n",
       "      <td>aventurier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unisex</td>\n",
       "      <td>arman</td>\n",
       "      <td>aristocrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>norway</td>\n",
       "      <td>adid</td>\n",
       "      <td>garçon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geographical</td>\n",
       "      <td>emporio</td>\n",
       "      <td>vieillard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ingersoll</td>\n",
       "      <td>garcon</td>\n",
       "      <td>délinquant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>arman</td>\n",
       "      <td>stuhrling</td>\n",
       "      <td>écrivain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>navy</td>\n",
       "      <td>chronograph</td>\n",
       "      <td>politicien</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>emporio</td>\n",
       "      <td>men</td>\n",
       "      <td>escroc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pantalon</td>\n",
       "      <td>adh</td>\n",
       "      <td>orateur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>vest</td>\n",
       "      <td>chrono</td>\n",
       "      <td>érudit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CBOW    skip-gram       online\n",
       "0          femm       unisex   aventurier\n",
       "1        unisex        arman  aristocrate\n",
       "2        norway         adid       garçon\n",
       "3  geographical      emporio    vieillard\n",
       "4     ingersoll       garcon   délinquant\n",
       "5         arman    stuhrling     écrivain\n",
       "6          navy  chronograph   politicien\n",
       "7       emporio          men       escroc\n",
       "8      pantalon          adh      orateur\n",
       "9          vest       chrono       érudit"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=\"homme\"\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    token = stemmer.stem(term) if \"online\"!=model_name else term\n",
    "    mpow = model.wv.most_similar([token])\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "print(\"Most similar words for word : \"+term)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for word : femme\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>homm</td>\n",
       "      <td>unisex</td>\n",
       "      <td>servante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unisex</td>\n",
       "      <td>femmecollect</td>\n",
       "      <td>mère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fashion</td>\n",
       "      <td>femmecouleur</td>\n",
       "      <td>fille</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ballerin</td>\n",
       "      <td>fashion</td>\n",
       "      <td>belle-mère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sandal</td>\n",
       "      <td>arman</td>\n",
       "      <td>fiancée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>srkz</td>\n",
       "      <td>noircomposit</td>\n",
       "      <td>compagne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bicolor</td>\n",
       "      <td>versac</td>\n",
       "      <td>sœur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>escarpin</td>\n",
       "      <td>bred</td>\n",
       "      <td>prostituée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bottin</td>\n",
       "      <td>dkny</td>\n",
       "      <td>nourrice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>arman</td>\n",
       "      <td>cendriyon</td>\n",
       "      <td>demi-sœur</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CBOW     skip-gram      online\n",
       "0      homm        unisex    servante\n",
       "1    unisex  femmecollect        mère\n",
       "2   fashion  femmecouleur       fille\n",
       "3  ballerin       fashion  belle-mère\n",
       "4    sandal         arman     fiancée\n",
       "5      srkz  noircomposit    compagne\n",
       "6   bicolor        versac        sœur\n",
       "7  escarpin          bred  prostituée\n",
       "8    bottin          dkny    nourrice\n",
       "9     arman     cendriyon   demi-sœur"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=\"femme\"\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    token = stemmer.stem(term) if \"online\"!=model_name else term\n",
    "    mpow = model.wv.most_similar([token])\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "print(\"Most similar words for word : \"+term)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar words for word : xbox\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>travel</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>playstation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>octan</td>\n",
       "      <td>wii</td>\n",
       "      <td>gamecube</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>erupt</td>\n",
       "      <td>playstat</td>\n",
       "      <td>dreamcast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>krakau</td>\n",
       "      <td>controll</td>\n",
       "      <td>psp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>embedded</td>\n",
       "      <td>scrib</td>\n",
       "      <td>wii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>subliminal</td>\n",
       "      <td>unleashed</td>\n",
       "      <td>neo-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hauck</td>\n",
       "      <td>cruz</td>\n",
       "      <td>mega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>robocop</td>\n",
       "      <td>kobo</td>\n",
       "      <td>advance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>qnt</td>\n",
       "      <td>storio</td>\n",
       "      <td>famicom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cobby</td>\n",
       "      <td>scuf</td>\n",
       "      <td>nintendo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CBOW  skip-gram       online\n",
       "0      travel  microsoft  playstation\n",
       "1       octan        wii     gamecube\n",
       "2       erupt   playstat    dreamcast\n",
       "3      krakau   controll          psp\n",
       "4    embedded      scrib          wii\n",
       "5  subliminal  unleashed      neo-geo\n",
       "6       hauck       cruz         mega\n",
       "7     robocop       kobo      advance\n",
       "8         qnt     storio      famicom\n",
       "9       cobby       scuf     nintendo"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term=\"xbox\"\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    token = stemmer.stem(term) if \"online\"!=model_name else term\n",
    "    mpow = model.wv.most_similar([token])\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "print(\"Most similar words for word : \"+term)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lapin</td>\n",
       "      <td>coquin</td>\n",
       "      <td>reine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jungl</td>\n",
       "      <td>sorcier</td>\n",
       "      <td>belle-mère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>halloween</td>\n",
       "      <td>ruin</td>\n",
       "      <td>brunehilde</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>romant</td>\n",
       "      <td>poupon</td>\n",
       "      <td>régente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pap</td>\n",
       "      <td>paon</td>\n",
       "      <td>reine-mère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amour</td>\n",
       "      <td>redecouvr</td>\n",
       "      <td>belle-sœur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>eleph</td>\n",
       "      <td>bstick</td>\n",
       "      <td>veuve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lion</td>\n",
       "      <td>tendress</td>\n",
       "      <td>mère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>canard</td>\n",
       "      <td>fev</td>\n",
       "      <td>demi-sœur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>poisson</td>\n",
       "      <td>jungl</td>\n",
       "      <td>nièce</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CBOW  skip-gram      online\n",
       "0      lapin     coquin       reine\n",
       "1      jungl    sorcier  belle-mère\n",
       "2  halloween       ruin  brunehilde\n",
       "3     romant     poupon     régente\n",
       "4        pap       paon  reine-mère\n",
       "5      amour  redecouvr  belle-sœur\n",
       "6      eleph     bstick       veuve\n",
       "7       lion   tendress        mère\n",
       "8     canard        fev   demi-sœur\n",
       "9    poisson      jungl       nièce"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_positif = [\"femme\",\"roi\"]\n",
    "terms_negatif = [\"homme\"]\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    token_positif = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms_positif]\n",
    "    token_negativ = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms_negatif]\n",
    "    \n",
    "    mpow = model.wv.most_similar(positive=token_positif, negative=token_negativ)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>montan</td>\n",
       "      <td>arizon</td>\n",
       "      <td>ségovie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gourmandis</td>\n",
       "      <td>autrich</td>\n",
       "      <td>madrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flex</td>\n",
       "      <td>grec</td>\n",
       "      <td>alicante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>alabam</td>\n",
       "      <td>vilain</td>\n",
       "      <td>aix-en-provence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neon</td>\n",
       "      <td>colomb</td>\n",
       "      <td>ancône</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>liberty</td>\n",
       "      <td>entrecrois</td>\n",
       "      <td>séville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lichtertanz</td>\n",
       "      <td>ric</td>\n",
       "      <td>malaga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>canc</td>\n",
       "      <td>nigeri</td>\n",
       "      <td>andalousie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cub</td>\n",
       "      <td>manil</td>\n",
       "      <td>alger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>handbag</td>\n",
       "      <td>cancun</td>\n",
       "      <td>avignon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          CBOW   skip-gram           online\n",
       "0       montan      arizon          ségovie\n",
       "1   gourmandis     autrich           madrid\n",
       "2         flex        grec         alicante\n",
       "3       alabam      vilain  aix-en-provence\n",
       "4         neon      colomb           ancône\n",
       "5      liberty  entrecrois          séville\n",
       "6  lichtertanz         ric           malaga\n",
       "7         canc      nigeri       andalousie\n",
       "8          cub       manil            alger\n",
       "9      handbag      cancun          avignon"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_positif = [\"espagne\",\"paris\"]\n",
    "terms_negatif = [\"france\"]\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    token_positif = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms_positif]\n",
    "    token_negativ = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms_negatif]\n",
    "    \n",
    "    mpow = model.wv.most_similar(positive=token_positif, negative=token_negativ)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict output word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>infiniteshopping</td>\n",
       "      <td>referent</td>\n",
       "      <td>ci-dessous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>present</td>\n",
       "      <td>appartient</td>\n",
       "      <td>ci-dessus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neuv</td>\n",
       "      <td>lign</td>\n",
       "      <td>ci-après</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vot</td>\n",
       "      <td>main</td>\n",
       "      <td>l'article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sou</td>\n",
       "      <td>sac</td>\n",
       "      <td>infra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>presen</td>\n",
       "      <td>reduit</td>\n",
       "      <td>paragraphe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>desig</td>\n",
       "      <td>prix</td>\n",
       "      <td>bibliographie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pres</td>\n",
       "      <td>if</td>\n",
       "      <td>liste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>presentat</td>\n",
       "      <td>couleur</td>\n",
       "      <td>ci-contre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cha</td>\n",
       "      <td>photo</td>\n",
       "      <td>section</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               CBOW   skip-gram         online\n",
       "0  infiniteshopping    referent     ci-dessous\n",
       "1           present  appartient      ci-dessus\n",
       "2              neuv        lign       ci-après\n",
       "3               vot        main      l'article\n",
       "4               sou         sac          infra\n",
       "5            presen      reduit     paragraphe\n",
       "6             desig        prix  bibliographie\n",
       "7              pres          if          liste\n",
       "8         presentat     couleur      ci-contre\n",
       "9               cha       photo        section"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [\"voir\",\"la\"]\n",
    "\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    tokens = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms]\n",
    "    \n",
    "    mpow = model.predict_output_word(tokens)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>galaxy</td>\n",
       "      <td>ace</td>\n",
       "      <td>acier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ace</td>\n",
       "      <td>galaxy</td>\n",
       "      <td>aluminium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>express</td>\n",
       "      <td>trend</td>\n",
       "      <td>coque</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>not</td>\n",
       "      <td>cor</td>\n",
       "      <td>former</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stuff</td>\n",
       "      <td>express</td>\n",
       "      <td>béton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>trend</td>\n",
       "      <td>not</td>\n",
       "      <td>métallique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ref</td>\n",
       "      <td>franc</td>\n",
       "      <td>protéger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xcov</td>\n",
       "      <td>plai</td>\n",
       "      <td>remplacer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plai</td>\n",
       "      <td>drapeau</td>\n",
       "      <td>fabriquer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>soupl</td>\n",
       "      <td>soupl</td>\n",
       "      <td>conçue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CBOW skip-gram      online\n",
       "0   galaxy       ace       acier\n",
       "1      ace    galaxy   aluminium\n",
       "2  express     trend       coque\n",
       "3      not       cor      former\n",
       "4    stuff   express       béton\n",
       "5    trend       not  métallique\n",
       "6      ref     franc    protéger\n",
       "7     xcov      plai   remplacer\n",
       "8     plai   drapeau   fabriquer\n",
       "9    soupl     soupl      conçue"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [\"coque\",'pour',\"samsung\"]\n",
    "\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    tokens = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms]\n",
    "    \n",
    "    mpow = model.predict_output_word(tokens)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>montr</td>\n",
       "      <td>chronograph</td>\n",
       "      <td>d'affaires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>genr</td>\n",
       "      <td>stuhrling</td>\n",
       "      <td>vieil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ditl</td>\n",
       "      <td>hood</td>\n",
       "      <td>d’affaires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>geographical</td>\n",
       "      <td>chemis</td>\n",
       "      <td>politique</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>field</td>\n",
       "      <td>tissot</td>\n",
       "      <td>d'état</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chronograph</td>\n",
       "      <td>victorinox</td>\n",
       "      <td>d'église</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ferry</td>\n",
       "      <td>montr</td>\n",
       "      <td>cet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>box</td>\n",
       "      <td>bruc</td>\n",
       "      <td>jeune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vet</td>\n",
       "      <td>swiss</td>\n",
       "      <td>néandertal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>boxer</td>\n",
       "      <td>anarchy</td>\n",
       "      <td>d’état</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CBOW    skip-gram      online\n",
       "0         montr  chronograph  d'affaires\n",
       "1          genr    stuhrling       vieil\n",
       "2          ditl         hood  d’affaires\n",
       "3  geographical       chemis   politique\n",
       "4         field       tissot      d'état\n",
       "5   chronograph   victorinox    d'église\n",
       "6         ferry        montr         cet\n",
       "7           box         bruc       jeune\n",
       "8           vet        swiss  néandertal\n",
       "9         boxer      anarchy      d’état"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [\"homme\"]\n",
    "\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    tokens = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms]\n",
    "    \n",
    "    mpow = model.predict_output_word(tokens)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CBOW</th>\n",
       "      <th>skip-gram</th>\n",
       "      <th>online</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>montr</td>\n",
       "      <td>montr</td>\n",
       "      <td>sa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ditl</td>\n",
       "      <td>cendriyon</td>\n",
       "      <td>jeune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cendriyon</td>\n",
       "      <td>dkny</td>\n",
       "      <td>d'affaires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chaussur</td>\n",
       "      <td>bred</td>\n",
       "      <td>mariée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>genr</td>\n",
       "      <td>bulov</td>\n",
       "      <td>enceinte</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vet</td>\n",
       "      <td>revon</td>\n",
       "      <td>nue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bagu</td>\n",
       "      <td>genev</td>\n",
       "      <td>adultère</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tong</td>\n",
       "      <td>hubert</td>\n",
       "      <td>assassinée</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hilfig</td>\n",
       "      <td>lublin</td>\n",
       "      <td>fatale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>giorgio</td>\n",
       "      <td>skagen</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CBOW  skip-gram      online\n",
       "0      montr      montr          sa\n",
       "1       ditl  cendriyon       jeune\n",
       "2  cendriyon       dkny  d'affaires\n",
       "3   chaussur       bred      mariée\n",
       "4       genr      bulov    enceinte\n",
       "5        vet      revon         nue\n",
       "6       bagu      genev    adultère\n",
       "7       tong     hubert  assassinée\n",
       "8     hilfig     lublin      fatale\n",
       "9    giorgio     skagen       homme"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms = [\"femme\"]\n",
    "\n",
    "\n",
    "df_ = []\n",
    "columns = []\n",
    "for model_name, model in model_dic.items():\n",
    "    tokens = [stemmer.stem(term) if \"online\"!=model_name else term for term in terms]\n",
    "    \n",
    "    mpow = model.predict_output_word(tokens)\n",
    "    if mpow is None:\n",
    "        df_.append([\"\" for k in range(10)])\n",
    "    else:\n",
    "        df_.append([k[0] for k in mpow])\n",
    "    columns.append(model_name)\n",
    "pd.DataFrame(np.array(df_).T, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_clean = pd.read_csv(\"data/cdiscount_test_clean.csv\").fillna(\"\")\n",
    "data_train_clean = pd.read_csv(\"data/cdiscount_train_clean.csv\").fillna(\"\")\n",
    "\n",
    "train_array_token_wstem = [line.split(\" \") for line in data_train_clean[\"Description\"].values]\n",
    "test_array_token_wstem = [line.split(\" \") for line in data_test_clean[\"Description\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_mean(lines):\n",
    "    features = [MODEL[x] for x  in lines if x in MODEL]\n",
    "    if features == []:   \n",
    "        fm =np.ones(F_SIZE)\n",
    "    else :\n",
    "        fm = np.mean(features,axis=0)\n",
    "    return fm\n",
    "\n",
    "def get_matrix_features_means(X):\n",
    "    X_embedded_ = list(map(get_features_mean, X))\n",
    "    X_embedded = np.vstack(X_embedded_)\n",
    "    return X_embedded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time conversion : 10 seconds\n",
      "Shape Matrix : (95000,300)\n",
      "Time conversion : 0 seconds\n",
      "Shape Matrix : (5000,300)\n",
      "{'t_train': 10.871941328048706, 't_test': 0.5806784629821777, 'sg': 1}\n",
      "Time conversion : 11 seconds\n",
      "Shape Matrix : (95000,300)\n",
      "Time conversion : 0 seconds\n",
      "Shape Matrix : (5000,300)\n",
      "{'t_train': 11.681430339813232, 't_test': 0.5803375244140625, 'sg': 1}\n",
      "Time conversion : 9 seconds\n",
      "Shape Matrix : (95000,300)\n",
      "Time conversion : 0 seconds\n",
      "Shape Matrix : (5000,300)\n",
      "{'t_train': 9.758267164230347, 't_test': 0.6593830585479736, 'sg': 1}\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"CBOW\",\"skip-gram\", \"online\"]:\n",
    "    \n",
    "    if \"online\" == model_name:\n",
    "        X_train = train_array_token_wstem\n",
    "        X_test = test_array_token_wstem\n",
    "    else:\n",
    "        X_train = train_array_token\n",
    "        X_test = test_array_token\n",
    "    \n",
    "    model = model_dic[model_name]\n",
    "    MODEL = model\n",
    "    F_SIZE = Features_dimension\n",
    "\n",
    "    ts = time.time()\n",
    "    X_embedded_train = get_matrix_features_means(X_train)\n",
    "    te = time.time()\n",
    "    t_train = te-ts\n",
    "    #np.save(embedded_train_dir, X_embedded_train)\n",
    "    print(\"Time conversion : %d seconds\"%t_train)\n",
    "    print(\"Shape Matrix : (%d,%d)\"%X_embedded_train.shape)\n",
    "    np.save(DATA_OUTPUT_DIR +\"/embedded_train_nb_hash_\"+model_name, X_embedded_train)\n",
    "\n",
    "    \n",
    "    ts = time.time()\n",
    "    X_embedded_test = get_matrix_features_means(X_test)\n",
    "    te = time.time()\n",
    "    t_test = te-ts\n",
    "    #np.save(embedded_test_dir, X_embedded_test)\n",
    "    print(\"Time conversion : %d seconds\"%t_test)\n",
    "    print(\"Shape Matrix : (%d,%d)\"%X_embedded_test.shape)\n",
    "    np.save(DATA_OUTPUT_DIR +\"/embedded_test_nb_hash_\"+model_name, X_embedded_test)\n",
    "    \n",
    "    metadata = {\"t_train\" : t_train, \"t_test\" : t_test, \"sg\":sg}\n",
    "    print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.68843603e+00,  1.93454778e+00, -1.81924117e+00,  2.36969948e+00,\n",
       "        9.32004392e-01,  1.25195098e+00,  8.65360320e-01,  3.11363190e-01,\n",
       "        6.06419086e-01,  1.43122864e+00,  1.65650344e+00, -3.67380810e+00,\n",
       "        1.87034404e+00,  1.74155509e+00, -5.33656299e-01,  1.40374994e+00,\n",
       "        2.30875421e+00,  1.79799902e+00, -1.87658596e+00,  1.29379809e+00,\n",
       "        9.08876181e-01,  1.08965196e-01, -1.40824032e+00,  8.72196436e-01,\n",
       "        1.08273089e+00,  7.29817152e-01, -1.11542833e+00,  1.52417982e+00,\n",
       "        1.71380103e+00, -2.30002356e+00,  1.15143669e+00, -2.83064008e-01,\n",
       "        2.14521900e-01,  8.66827071e-01,  7.54454792e-01,  2.86816597e-01,\n",
       "        5.41400373e-01, -7.38874137e-01,  5.10816514e-01, -1.25636995e+00,\n",
       "       -8.32316935e-01,  3.15392661e+00, -6.42400444e-01, -1.62124023e-01,\n",
       "       -1.09802079e+00,  1.84242070e+00, -3.25098783e-01, -6.75076485e-01,\n",
       "        1.25538635e+00,  9.76222456e-01, -1.26038420e+00, -8.73921692e-01,\n",
       "       -4.83060241e-01, -1.63996017e+00,  7.62541443e-02,  8.87569129e-01,\n",
       "        1.44738925e+00, -9.39991832e-01,  5.22625744e-01, -1.13829386e+00,\n",
       "        2.46780300e+00,  1.03674316e+00, -3.46387550e-02,  5.59141755e-01,\n",
       "       -1.85830843e+00,  1.89094067e+00, -2.26592970e+00, -1.27904451e+00,\n",
       "        1.20280313e+00, -1.99019861e+00, -1.18200147e+00, -1.26226985e+00,\n",
       "       -2.97760367e-01,  1.58452189e+00,  1.69851220e+00,  4.03091172e-03,\n",
       "        1.18817770e+00,  9.70204413e-01,  4.13892627e-01, -1.02979946e+00,\n",
       "        2.23877263e+00, -1.44865227e+00, -5.04627824e-01,  8.68076801e-01,\n",
       "        8.29642490e-02,  2.04609823e+00, -1.05298305e+00,  6.09300554e-01,\n",
       "       -3.04428399e-01,  2.73707962e+00, -4.90044475e-01,  6.93703949e-01,\n",
       "        6.47519588e-01, -1.02498055e+00,  4.15770024e-01,  7.80640066e-01,\n",
       "       -4.63584423e-01, -2.49082476e-01, -7.62456775e-01, -5.47676980e-01,\n",
       "        1.17528290e-01, -4.62611139e-01,  2.14557275e-01, -3.28053188e+00,\n",
       "       -5.41767597e-01, -1.62989473e+00,  7.04871237e-01, -3.26627374e+00,\n",
       "       -1.94655013e+00, -2.44072461e+00,  3.53704125e-01,  5.20247161e-01,\n",
       "       -6.92556024e-01, -8.00403114e-03,  4.45334911e-01,  1.83195725e-01,\n",
       "        2.57963538e+00, -1.73451412e+00,  1.46722376e+00, -1.63455665e+00,\n",
       "       -8.58749390e-01, -6.21192455e-01, -1.50854373e+00, -5.48384249e-01,\n",
       "        1.58481568e-01,  5.74040897e-02, -2.33555293e+00, -1.24846363e+00,\n",
       "        1.14320815e+00,  2.19661355e+00, -1.67331612e+00, -4.21535254e-01,\n",
       "       -1.08153939e+00,  1.16735470e+00,  1.04143536e+00,  3.06623054e+00,\n",
       "        1.65813851e+00, -1.17980875e-01,  7.62855887e-01,  8.76870602e-02,\n",
       "       -3.08444858e+00, -8.69260669e-01, -6.04443192e-01, -1.61660045e-01,\n",
       "       -8.61184120e-01, -2.36440158e+00,  5.85857093e-01, -1.39690363e+00,\n",
       "       -8.98482919e-01,  1.49133730e+00,  1.13904285e+00,  1.06437540e+00,\n",
       "       -1.32740811e-01, -2.40807557e+00,  1.03752029e+00, -2.68450469e-01,\n",
       "       -1.56857455e+00,  5.13491571e-01,  1.27838290e+00,  3.60189891e+00,\n",
       "       -7.12578058e-01,  1.14855134e+00, -9.21212018e-01,  1.84563351e+00,\n",
       "       -1.35468924e+00,  5.08043587e-01, -7.86122531e-02,  1.48000047e-01,\n",
       "       -3.08121383e-01,  2.60533619e+00,  1.17474757e-01, -2.68221569e+00,\n",
       "       -2.11171627e+00,  6.67897880e-01,  7.17338204e-01, -1.36855912e+00,\n",
       "        5.55815279e-01, -2.61767530e+00,  7.53945827e-01, -2.16935322e-01,\n",
       "       -1.07531153e-01, -9.10443187e-01, -1.41226697e+00,  1.81568074e+00,\n",
       "       -7.87165314e-02, -8.01170245e-02,  2.15358090e+00, -1.11790109e+00,\n",
       "        4.41408157e-01, -2.03346205e+00,  2.00758553e+00, -9.28918600e-01,\n",
       "       -2.80272388e+00,  9.71888959e-01, -3.24676514e+00, -3.38747120e+00,\n",
       "       -8.82310331e-01,  5.86733460e-01,  4.13469267e+00, -1.71811211e+00,\n",
       "        1.64829624e+00,  1.12822413e+00, -8.73017550e-01,  3.29645097e-01,\n",
       "       -4.39161003e-01, -2.36133933e-02,  1.20484522e-02,  6.67026162e-01,\n",
       "        1.21784627e+00, -6.66718662e-01,  1.17255211e+00, -2.04697937e-01,\n",
       "        1.69140399e+00,  1.07980084e+00, -2.47413158e+00,  2.09850931e+00,\n",
       "       -6.12240016e-01, -7.53843009e-01, -1.34083271e+00, -5.60064673e-01,\n",
       "        1.55512488e+00,  1.69336259e+00,  5.39195061e-01, -9.16285992e-01,\n",
       "        3.11728507e-01,  8.77962768e-01,  1.99047327e+00, -1.01559389e+00,\n",
       "        4.54195142e-01, -2.52110958e-01,  4.88547832e-01,  1.10475075e+00,\n",
       "        1.73281097e+00,  1.78320634e+00,  1.45284402e+00, -1.05085388e-01,\n",
       "        1.55221033e+00, -1.42480302e+00,  6.98454022e-01,  7.52862453e-01,\n",
       "       -1.81827140e+00, -1.24825382e+00,  1.18460631e+00,  1.52688134e+00,\n",
       "        1.00072527e+00,  1.75584793e+00,  1.83837724e+00, -2.25422144e+00,\n",
       "        7.82507837e-01, -1.09857738e+00,  3.19284648e-01, -9.82456982e-01,\n",
       "        1.89534295e+00, -2.64766812e+00,  1.82309616e+00,  4.94696081e-01,\n",
       "        9.68492806e-01, -1.67260408e+00, -1.97256851e+00, -4.63027775e-01,\n",
       "       -6.73265040e-01, -1.25769424e+00,  3.03554088e-01,  1.96161973e+00,\n",
       "        3.92474145e-01, -1.71958745e+00, -8.76169503e-01, -6.63521230e-01,\n",
       "        2.60092998e+00, -7.78240681e-01,  9.60782945e-01,  1.20106184e+00,\n",
       "        1.42938304e+00,  2.14928344e-01,  1.43222558e+00, -6.82170331e-01,\n",
       "       -4.19037193e-01, -1.89129150e+00,  5.24691403e-01,  3.05440158e-01,\n",
       "        2.47658923e-01, -3.37442517e-01, -1.08417638e-01, -2.13882208e+00,\n",
       "       -1.29791582e+00,  4.53739196e-01,  1.67676663e+00, -2.65482455e-01,\n",
       "       -1.88126493e+00, -1.19294786e+00, -1.84755564e+00,  3.50193322e-01,\n",
       "        4.38239634e-01, -2.00624895e+00,  1.60679221e+00,  7.75282681e-01,\n",
       "       -8.51706386e-01, -5.76808453e-01,  7.63676286e-01, -5.04155271e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"homme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.syn0[model.wv.vocab[\"homme\"].index] == model[\"homme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50130, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.syn1neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "419"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vh = model.wv.vocab[\"homme\"]\n",
    "vh.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {
    "height": "279px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
